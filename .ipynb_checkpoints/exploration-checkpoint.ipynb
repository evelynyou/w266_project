{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## you/metz w266 project data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 232\r\n",
      "-rw-rw-r-- 1 evelyn_you evelyn_you    588 Jul 20 07:01  README.md\r\n",
      "-rw-rw-r-- 1 evelyn_you evelyn_you 143730 Jul 20 07:01 'Screen Shot 2020-07-18 at 2.45.50 PM.png'\r\n",
      "drwxrwxr-x 3 evelyn_you evelyn_you   4096 Jul 21 05:19  bin\r\n",
      "drwxrwxr-x 6 evelyn_you evelyn_you   4096 Jul 21 21:57  data\r\n",
      "-rw-rw-r-- 1 evelyn_you evelyn_you  39976 Jul 21 22:11  exploration.ipynb\r\n",
      "drwxrwxr-x 9 evelyn_you evelyn_you   4096 Jul 21 20:16  goemotions\r\n",
      "drwxrwxr-x 3 evelyn_you evelyn_you   4096 Jul 21 05:18  lib\r\n",
      "drwxrwxr-x 2 evelyn_you evelyn_you   4096 Jul 20 07:01  model_trained\r\n",
      "drwxrwxr-x 2 evelyn_you evelyn_you   4096 Jul 21 03:38  plots\r\n",
      "-rw-rw-r-- 1 evelyn_you evelyn_you    289 Jul 21 05:18  pyvenv.cfg\r\n",
      "-rw-rw-r-- 1 evelyn_you evelyn_you    715 Jul 20 07:01  run_commands\r\n",
      "-rw-rw-r-- 1 evelyn_you evelyn_you    803 Jul 20 07:01  run_evaluation.sh\r\n",
      "-rw-rw-r-- 1 evelyn_you evelyn_you    847 Jul 20 07:01  run_training.sh\r\n",
      "-rw-rw-r-- 1 evelyn_you evelyn_you   1849 Jul 20 07:01  trm_common_commands.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['processed', 'empatheticdialogues', '.ipynb_checkpoints', 'goemotions']\n"
     ]
    }
   ],
   "source": [
    "#data_dir=\"/home/travismetz/w266_project/data/empatheticdialogues\"\n",
    "data_dir=\"data\"\n",
    "data_folders=os.listdir(data_dir)\n",
    "print (data_folders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed \n",
      " ['all_ed_data.csv']\n",
      "------------------------------\n",
      "empatheticdialogues \n",
      " ['valid.csv', 'train.csv', 'test.csv']\n",
      "------------------------------\n",
      ".ipynb_checkpoints \n",
      " []\n",
      "------------------------------\n",
      "goemotions \n",
      " ['goemotions_3.csv', 'goemotions_2.csv', 'goemotions_1.csv']\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for data_folder in data_folders:\n",
    "    print(data_folder,'\\n',os.listdir(os.path.join(data_dir,data_folder)))\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### empatheticdialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 2355: expected 8 fields, saw 10\\nSkipping line 36628: expected 8 fields, saw 12\\nSkipping line 49433: expected 8 fields, saw 10\\nSkipping line 56957: expected 8 fields, saw 10\\nSkipping line 65019: expected 8 fields, saw 10\\n'\n"
     ]
    }
   ],
   "source": [
    "data_folder='empatheticdialogues'\n",
    "file_name='train.csv'\n",
    "train=pd.read_csv(os.path.join(data_dir,data_folder,file_name),error_bad_lines=False)\n",
    "#there are bad lines where columns got out of sequence so need error_bad_lines flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conv_id                                               hit:0_conv:1\n",
       "utterance_idx                                                    1\n",
       "context                                                sentimental\n",
       "prompt           I remember going to the fireworks with my best...\n",
       "speaker_idx                                                      1\n",
       "utterance        I remember going to see the fireworks with my ...\n",
       "selfeval                                               5|5|5_2|2|5\n",
       "tags                                                           NaN\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76668, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hit:0_conv:1', 'hit:1_conv:2', 'hit:1_conv:3', ...,\n",
       "       'hit:12423_conv:24846', 'hit:12424_conv:24848',\n",
       "       'hit:12424_conv:24849'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.conv_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>utterance</th>\n",
       "      <th>selfeval</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>1</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>1</td>\n",
       "      <td>I remember going to see the fireworks with my ...</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>2</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>0</td>\n",
       "      <td>Was this a friend you were in love with_comma_...</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>3</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>1</td>\n",
       "      <td>This was a best friend. I miss her.</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>4</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>0</td>\n",
       "      <td>Where has she gone?</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>5</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>1</td>\n",
       "      <td>We no longer talk.</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        conv_id  utterance_idx      context  \\\n",
       "0  hit:0_conv:1              1  sentimental   \n",
       "1  hit:0_conv:1              2  sentimental   \n",
       "2  hit:0_conv:1              3  sentimental   \n",
       "3  hit:0_conv:1              4  sentimental   \n",
       "4  hit:0_conv:1              5  sentimental   \n",
       "\n",
       "                                              prompt  speaker_idx  \\\n",
       "0  I remember going to the fireworks with my best...            1   \n",
       "1  I remember going to the fireworks with my best...            0   \n",
       "2  I remember going to the fireworks with my best...            1   \n",
       "3  I remember going to the fireworks with my best...            0   \n",
       "4  I remember going to the fireworks with my best...            1   \n",
       "\n",
       "                                           utterance     selfeval tags  \n",
       "0  I remember going to see the fireworks with my ...  5|5|5_2|2|5  NaN  \n",
       "1  Was this a friend you were in love with_comma_...  5|5|5_2|2|5  NaN  \n",
       "2                This was a best friend. I miss her.  5|5|5_2|2|5  NaN  \n",
       "3                                Where has she gone?  5|5|5_2|2|5  NaN  \n",
       "4                                 We no longer talk.  5|5|5_2|2|5  NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "surprised       3956\n",
       "excited         2935\n",
       "angry           2740\n",
       "proud           2719\n",
       "annoyed         2642\n",
       "sad             2634\n",
       "afraid          2510\n",
       "lonely          2503\n",
       "grateful        2487\n",
       "terrified       2487\n",
       "guilty          2463\n",
       "anxious         2456\n",
       "disgusted       2447\n",
       "confident       2440\n",
       "anticipating    2439\n",
       "hopeful         2404\n",
       "furious         2394\n",
       "impressed       2381\n",
       "disappointed    2356\n",
       "nostalgic       2350\n",
       "joyful          2346\n",
       "jealous         2329\n",
       "prepared        2292\n",
       "content         2214\n",
       "devastated      2192\n",
       "embarrassed     2191\n",
       "sentimental     2073\n",
       "caring          2054\n",
       "trusting        2001\n",
       "ashamed         1976\n",
       "apprehensive    1822\n",
       "faithful        1435\n",
       "Name: context, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.context.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: sentimental\n",
      "prompt: I remember going to the fireworks with my best friend. There was a lot of people_comma_ but it only felt like us in the world.\n",
      "selfeval: 5|5|5_2|2|5\n",
      "\n",
      "\n",
      "I remember going to see the fireworks with my best friend. It was the first time we ever spent time alone together. Although there was a lot of people_comma_ we felt like the only people in the world.\n",
      "Was this a friend you were in love with_comma_ or just a best friend?\n",
      "This was a best friend. I miss her.\n",
      "Where has she gone?\n",
      "We no longer talk.\n",
      "Oh was this something that happened because of an argument?\n"
     ]
    }
   ],
   "source": [
    "def print_conversation(data,conv_id):\n",
    "    conversation=data[data.conv_id==conv_id]\n",
    "    print ('context:',conversation.context.iloc[0])\n",
    "    print('prompt:',conversation.prompt.iloc[0])\n",
    "    print('selfeval:',conversation.selfeval.iloc[0])\n",
    "    print('\\n')\n",
    "    for utterance in conversation.utterance:\n",
    "        print(utterance)\n",
    "\n",
    "conv_id='hit:0_conv:1'\n",
    "print_conversation(train,conv_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                hit:0_conv:1\n",
       "1        hit:10000_conv:20000\n",
       "2        hit:10000_conv:20001\n",
       "3        hit:10001_conv:20002\n",
       "4        hit:10002_conv:20004\n",
       "                 ...         \n",
       "17834     hit:9999_conv:19999\n",
       "17835       hit:999_conv:1998\n",
       "17836       hit:999_conv:1999\n",
       "17837         hit:99_conv:198\n",
       "17838           hit:9_conv:19\n",
       "Name: conv_id, Length: 17839, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_list=train.groupby('conv_id').last().reset_index().conv_id\n",
    "conversation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: sentimental\n",
      "prompt: I remember going to the fireworks with my best friend. There was a lot of people_comma_ but it only felt like us in the world.\n",
      "selfeval: 5|5|5_2|2|5\n",
      "\n",
      "\n",
      "I remember going to see the fireworks with my best friend. It was the first time we ever spent time alone together. Although there was a lot of people_comma_ we felt like the only people in the world.\n",
      "Was this a friend you were in love with_comma_ or just a best friend?\n",
      "This was a best friend. I miss her.\n",
      "Where has she gone?\n",
      "We no longer talk.\n",
      "Oh was this something that happened because of an argument?\n",
      "\n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "context: surprised\n",
      "prompt: My girlfriend got me a toad today! I was so shocked and happy!\n",
      "selfeval: 5|5|5_5|5|5\n",
      "\n",
      "\n",
      "My girlfriend got me a pet toad today!\n",
      "Do you like toads?\n",
      "I do! I was so happy when I opened the box and that fat mofo jumped out!\n",
      "That was nice of your girlfriend_comma_ do you love her?\n",
      "\n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "context: impressed\n",
      "prompt: I really like the new paint job on my house.\n",
      "selfeval: 5|5|5_5|5|5\n",
      "\n",
      "\n",
      "I really like the new paint job on my house.\n",
      "That's nice. What color did you paint it?\n",
      "I went with blue and yellow.\n",
      "Those are swell colors! I am sure they will bring any guests much joy and merriment.\n",
      "\n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "context: lonely\n",
      "prompt: I went to the skating rink all by myself today because my friends ditched me. I was so sad.\n",
      "selfeval: 5|5|5_3|3|5\n",
      "\n",
      "\n",
      "I went to the skating rink all by myself today because my friends ditched me.\n",
      "That's disappointing. I'm glad that you didn't let that stop you_comma_ and that you still went out and had a good time!\n",
      "Oh_comma_ it was a dreadful time. I never felt so alone as they played Smash Mouth's \"All Star\".\n",
      "Why weren't your friends able to come?\n",
      "\n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "context: ashamed\n",
      "prompt: I was walking on the road. I saw beggar and i did not help him\n",
      "selfeval: 5|5|5_4|4|5\n",
      "\n",
      "\n",
      "I was walking on the road. I saw a beggar and i didn't help him.\n",
      "Wow_comma_ that's kinda mean\n",
      "yeah i know. i was in a hurry and i am ashamed of myself!!\n",
      "You think he will be there next time so you can help him?\n",
      "\n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "context: guilty\n",
      "prompt: Eating someone's cake at work only to realize that there wasn't anymore left for them\n",
      "selfeval: 4|4|5_5|5|5\n",
      "\n",
      "\n",
      "I ate my co-worker's cake_comma_ which was in the fridge\n",
      "haha_comma_ was that intentional to get revenge on him/her. or just that you were hungry?\n",
      "I was hungry_comma_ I didn't' know it was his_comma_ and when he came back_comma_ there wasn't any cake remaining\n",
      "haha. Did you tell him about it?\n",
      "No_comma_ he doesn't knows\n",
      "\n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "context: nostalgic\n",
      "prompt: I was able to pull up on the internet pictures from where I lived as a kid. I felt like I was right back there.\n",
      "selfeval: 5|5|5_5|5|5\n",
      "\n",
      "\n",
      "I was able to pull up on the internet pictures from where I lived as a kid. I felt like I was right back there.\n",
      "Very nice. I bet you were full of joy to see them.\n",
      "It brought back so many memories.\n",
      "I bet they are very sentimental to you. Being able to remember those days must feel good\n",
      "\n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "context: surprised\n",
      "prompt: My little cousin gifted me for my birthday. I was so happy. He spent for me from his savings\n",
      "selfeval: 5|5|5_4|4|5\n",
      "\n",
      "\n",
      "My little cousin gifted me for my birthday\n",
      "Very sweet of him. Did he surprise you?\n",
      "Yeah definitely. it was very pleasant one at that. he earned that money while doing chores at home\n",
      "Nice! Hes a sweet kid. I bet that brought you joy as well.\n",
      "\n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "context: content\n",
      "prompt: I am happy with my current employer. Even though am getting a new job offer.\n",
      "selfeval: 5|5|5_5|5|5\n",
      "\n",
      "\n",
      "I am happy with my current employer. even though am getting a new jon offers\n",
      "That is good_comma_ maybe you can get a raise.\n",
      "Yeah feel like it. I very content with the current one as well\n",
      "Will you work there forever?\n",
      "\n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "context: furious\n",
      "prompt: I am so mad my flight got canceled.\n",
      "selfeval: 5|5|5_5|5|5\n",
      "\n",
      "\n",
      "I am so mad my flight got canceled.\n",
      "Ah that sucks_comma_ you were going for any business meeting?\n",
      "Yes and it was an important one.\n",
      "i hope you didn't lose that client\n",
      "\n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    }
   ],
   "source": [
    "for conv_id in conversation_list[0:10]:\n",
    "    print_conversation(train,conv_id)\n",
    "    print('\\n\\n','- '*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process for goemotions classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../goemotions/data'\n",
    "file_name = 'train.tsv'\n",
    "goemotions_train = pd.read_csv(os.path.join(data_dir,data_folder,file_name), sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43410, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>emotion_labels</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>27</td>\n",
       "      <td>eebbqej</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>27</td>\n",
       "      <td>ed00q6i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>2</td>\n",
       "      <td>eezlygj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>14</td>\n",
       "      <td>ed7ypvh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>3</td>\n",
       "      <td>ed0bdzj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe...</td>\n",
       "      <td>26</td>\n",
       "      <td>edvnz26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yes I heard abt the f bombs! That has to be wh...</td>\n",
       "      <td>15</td>\n",
       "      <td>ee3b6wu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We need more boards and to create a bit more s...</td>\n",
       "      <td>8,20</td>\n",
       "      <td>ef4qmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Damn youtube and outrage drama is super lucrat...</td>\n",
       "      <td>0</td>\n",
       "      <td>ed8wbdn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>It might be linked to the trust factor of your...</td>\n",
       "      <td>27</td>\n",
       "      <td>eczgv1o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           utterance emotion_labels  speaker\n",
       "0  My favourite food is anything I didn't have to...             27  eebbqej\n",
       "1  Now if he does off himself, everyone will thin...             27  ed00q6i\n",
       "2                     WHY THE FUCK IS BAYLESS ISOING              2  eezlygj\n",
       "3                        To make her feel threatened             14  ed7ypvh\n",
       "4                             Dirty Southern Wankers              3  ed0bdzj\n",
       "5  OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe...             26  edvnz26\n",
       "6  Yes I heard abt the f bombs! That has to be wh...             15  ee3b6wu\n",
       "7  We need more boards and to create a bit more s...           8,20  ef4qmod\n",
       "8  Damn youtube and outrage drama is super lucrat...              0  ed8wbdn\n",
       "9  It might be linked to the trust factor of your...             27  eczgv1o"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(goemotions_train.shape)\n",
    "goemotions_train.columns = [\"utterance\", \"emotion_labels\", \"speaker\"]\n",
    "\n",
    "## goemotions format\n",
    "goemotions_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_folder = 'empatheticdialogues'\n",
    "file_name = 'valid.csv'\n",
    "all_ed_data = pd.read_csv(os.path.join(data_dir, data_folder, file_name), error_bad_lines=False, \n",
    "                          usecols=[0, 1, 2, 3, 4, 5, 6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12030, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>utterance</th>\n",
       "      <th>selfeval</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:3_conv:6</td>\n",
       "      <td>1</td>\n",
       "      <td>terrified</td>\n",
       "      <td>Today_comma_as i was leaving for work in the m...</td>\n",
       "      <td>6</td>\n",
       "      <td>Today_comma_as i was leaving for work in the m...</td>\n",
       "      <td>4|5|5_5|5|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hit:3_conv:6</td>\n",
       "      <td>2</td>\n",
       "      <td>terrified</td>\n",
       "      <td>Today_comma_as i was leaving for work in the m...</td>\n",
       "      <td>7</td>\n",
       "      <td>Are you fine now?</td>\n",
       "      <td>4|5|5_5|5|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hit:3_conv:6</td>\n",
       "      <td>3</td>\n",
       "      <td>terrified</td>\n",
       "      <td>Today_comma_as i was leaving for work in the m...</td>\n",
       "      <td>6</td>\n",
       "      <td>Yeah_comma_i'm doing alright now_comma_ but wi...</td>\n",
       "      <td>4|5|5_5|5|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hit:3_conv:6</td>\n",
       "      <td>4</td>\n",
       "      <td>terrified</td>\n",
       "      <td>Today_comma_as i was leaving for work in the m...</td>\n",
       "      <td>7</td>\n",
       "      <td>Cool :) Is your car damaged a lot?</td>\n",
       "      <td>4|5|5_5|5|5</td>\n",
       "      <td>&lt;IRREGULAR_COLON_FORMAT&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hit:3_conv:6</td>\n",
       "      <td>5</td>\n",
       "      <td>terrified</td>\n",
       "      <td>Today_comma_as i was leaving for work in the m...</td>\n",
       "      <td>6</td>\n",
       "      <td>The car was badly damaged_comma_i veered outsi...</td>\n",
       "      <td>4|5|5_5|5|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hit:4_conv:9</td>\n",
       "      <td>1</td>\n",
       "      <td>surprised</td>\n",
       "      <td>I was walking through my hallway a few week ag...</td>\n",
       "      <td>8</td>\n",
       "      <td>A few weeks ago_comma_ I was walking through m...</td>\n",
       "      <td>5|5|5_3|5|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hit:4_conv:9</td>\n",
       "      <td>2</td>\n",
       "      <td>surprised</td>\n",
       "      <td>I was walking through my hallway a few week ag...</td>\n",
       "      <td>4</td>\n",
       "      <td>That's funny_comma_ hope he didn't give you a ...</td>\n",
       "      <td>5|5|5_3|5|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hit:4_conv:9</td>\n",
       "      <td>3</td>\n",
       "      <td>surprised</td>\n",
       "      <td>I was walking through my hallway a few week ag...</td>\n",
       "      <td>8</td>\n",
       "      <td>I may have let out a scream that will have him...</td>\n",
       "      <td>5|5|5_3|5|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hit:4_conv:9</td>\n",
       "      <td>4</td>\n",
       "      <td>surprised</td>\n",
       "      <td>I was walking through my hallway a few week ag...</td>\n",
       "      <td>4</td>\n",
       "      <td>I would probably scream also.</td>\n",
       "      <td>5|5|5_3|5|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hit:6_conv:12</td>\n",
       "      <td>1</td>\n",
       "      <td>excited</td>\n",
       "      <td>I'm overly excited today because will be flyin...</td>\n",
       "      <td>6</td>\n",
       "      <td>I'm overly excited because will be flying outs...</td>\n",
       "      <td>I have clicked the 'End Chat' button thank you...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         conv_id  utterance_idx    context  \\\n",
       "0   hit:3_conv:6              1  terrified   \n",
       "1   hit:3_conv:6              2  terrified   \n",
       "2   hit:3_conv:6              3  terrified   \n",
       "3   hit:3_conv:6              4  terrified   \n",
       "4   hit:3_conv:6              5  terrified   \n",
       "5   hit:4_conv:9              1  surprised   \n",
       "6   hit:4_conv:9              2  surprised   \n",
       "7   hit:4_conv:9              3  surprised   \n",
       "8   hit:4_conv:9              4  surprised   \n",
       "9  hit:6_conv:12              1    excited   \n",
       "\n",
       "                                              prompt  speaker_idx  \\\n",
       "0  Today_comma_as i was leaving for work in the m...            6   \n",
       "1  Today_comma_as i was leaving for work in the m...            7   \n",
       "2  Today_comma_as i was leaving for work in the m...            6   \n",
       "3  Today_comma_as i was leaving for work in the m...            7   \n",
       "4  Today_comma_as i was leaving for work in the m...            6   \n",
       "5  I was walking through my hallway a few week ag...            8   \n",
       "6  I was walking through my hallway a few week ag...            4   \n",
       "7  I was walking through my hallway a few week ag...            8   \n",
       "8  I was walking through my hallway a few week ag...            4   \n",
       "9  I'm overly excited today because will be flyin...            6   \n",
       "\n",
       "                                           utterance  \\\n",
       "0  Today_comma_as i was leaving for work in the m...   \n",
       "1                                  Are you fine now?   \n",
       "2  Yeah_comma_i'm doing alright now_comma_ but wi...   \n",
       "3                 Cool :) Is your car damaged a lot?   \n",
       "4  The car was badly damaged_comma_i veered outsi...   \n",
       "5  A few weeks ago_comma_ I was walking through m...   \n",
       "6  That's funny_comma_ hope he didn't give you a ...   \n",
       "7  I may have let out a scream that will have him...   \n",
       "8                      I would probably scream also.   \n",
       "9  I'm overly excited because will be flying outs...   \n",
       "\n",
       "                                            selfeval                      tags  \n",
       "0                                        4|5|5_5|5|5                       NaN  \n",
       "1                                        4|5|5_5|5|5                       NaN  \n",
       "2                                        4|5|5_5|5|5                       NaN  \n",
       "3                                        4|5|5_5|5|5  <IRREGULAR_COLON_FORMAT>  \n",
       "4                                        4|5|5_5|5|5                       NaN  \n",
       "5                                        5|5|5_3|5|5                       NaN  \n",
       "6                                        5|5|5_3|5|5                       NaN  \n",
       "7                                        5|5|5_3|5|5                       NaN  \n",
       "8                                        5|5|5_3|5|5                       NaN  \n",
       "9  I have clicked the 'End Chat' button thank you...                       NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(all_ed_data.shape)\n",
    "all_ed_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write this out to a file for reference later\n",
    "all_ed_data.to_csv ('data/processed/all_ed_data.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process for goemotions\n",
    "ed_for_goemotions = pd.DataFrame()\n",
    "ed_for_goemotions[\"utterance\"] = all_ed_data[\"utterance\"].str.replace(\"_comma_\", \", \", n=- 1, case=None, flags=0, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_for_goemotions[\"speaker\"] = all_ed_data[\"conv_id\"] + \"_\" + all_ed_data[\"utterance_idx\"].map(str) \\\n",
    "+ \"_\" + all_ed_data[\"speaker_idx\"].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today, as i was leaving for work in the mornin...</td>\n",
       "      <td>hit:3_conv:6_1_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are you fine now?</td>\n",
       "      <td>hit:3_conv:6_2_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yeah, i'm doing alright now,  but with minor i...</td>\n",
       "      <td>hit:3_conv:6_3_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cool :) Is your car damaged a lot?</td>\n",
       "      <td>hit:3_conv:6_4_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The car was badly damaged, i veered outside th...</td>\n",
       "      <td>hit:3_conv:6_5_6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           utterance           speaker\n",
       "0  Today, as i was leaving for work in the mornin...  hit:3_conv:6_1_6\n",
       "1                                  Are you fine now?  hit:3_conv:6_2_7\n",
       "2  Yeah, i'm doing alright now,  but with minor i...  hit:3_conv:6_3_6\n",
       "3                 Cool :) Is your car damaged a lot?  hit:3_conv:6_4_7\n",
       "4  The car was badly damaged, i veered outside th...  hit:3_conv:6_5_6"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed_for_goemotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write this out to a file for reference later\n",
    "ed_for_goemotions.to_csv ('data/processed/ed_for_goemotions.tsv', sep=\"\\t\", index = False, header = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
